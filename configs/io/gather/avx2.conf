register_size 256
{
  base_types = {"uint64_t", "uint32_t", "uint16_t", "uint8_t", "float", "double"}
  # provide one implementation for each base_type, use the same sequence as for base_types
  implementations = {
    "return _mm256_i64gather_epi64( reinterpret_cast<const long long int *> (p_DataPtr), p_vec,  sizeof(uint64_t) );",

    "return _mm256_i32gather_epi32( reinterpret_cast<const long long int *> (p_DataPtr), p_vec,  sizeof(uint32_t) );//a bit limited",

    "__m256i p_vec_1 = _mm256_srli_epi32(p_vec, 16);
     __m256i p_vec_2 = _mm256_srli_epi32(_mm256_slli_epi32(p_vec, 16),16);

     __m256i d_vec_1 = _mm256_i32gather_epi32(reinterpret_cast<const int *> (p_DataPtr), p_vec_1, 2);
     __m256i d_vec_2 = _mm256_i32gather_epi32(reinterpret_cast<const int *> (p_DataPtr), p_vec_2, 2);
     return _mm256_or_si256(
           _mm256_slli_epi32(d_vec_1, 16),
           _mm256_srli_epi32(_mm256_slli_epi64(d_vec_2, 16), 16)
     );//Possible accessible data range is 65.535/32.767",

     "__m256i p_vec_1 = _mm256_srli_epi32(p_vec, 24);
     __m256i p_vec_2 = _mm256_srli_epi32(_mm256_slli_epi32(p_vec, 8),24);
     __m256i p_vec_3 = _mm256_srli_epi32(_mm256_slli_epi32(p_vec, 16),24);
     __m256i p_vec_4 = _mm256_srli_epi32(_mm256_slli_epi32(p_vec, 24),24);

     __m256i d_vec_1 = _mm256_i32gather_epi32(reinterpret_cast<const int *> (p_DataPtr), p_vec_1, 1);
     __m256i d_vec_2 = _mm256_i32gather_epi32(reinterpret_cast<const int *> (p_DataPtr), p_vec_2, 1);
     __m256i d_vec_3 = _mm256_i32gather_epi32(reinterpret_cast<const int *> (p_DataPtr), p_vec_3, 1);
     __m256i d_vec_4 = _mm256_i32gather_epi32(reinterpret_cast<const int *> (p_DataPtr), p_vec_4, 1);

     return
     _mm256_or_si256(
        _mm256_or_si256(
           _mm256_slli_epi32(d_vec_1, 24),
           _mm256_srli_epi32(_mm256_slli_epi32(d_vec_2, 24), 8)
        ),
        _mm256_or_si256(
           _mm256_srli_epi32(_mm256_slli_epi32(d_vec_3, 24), 16),
           _mm256_srli_epi32(_mm256_slli_epi32(d_vec_4, 24), 24)
        )
     );//Possible accessible data range is 255/127",

     "return _mm256_i32gather_ps( reinterpret_cast<const float *> (p_DataPtr), p_vec,  sizeof(float) );//a bit limited",

     "return _mm256_i64gather_pd( reinterpret_cast<const double *> (p_DataPtr), p_vec,  sizeof(double) );"

  }
  # number of specialized template parameters exclusing the processing style
  nr_additional_template_parameters = 2
  # additional template specializations. If there is more than 1 template argument and more than 1 base type, follow this sequence: {base type 1/argument1, base type 1/argument 2, ..., base type n/argument 1, base type n/argument 2,..., base type n/argument m}
  template_parameters = {
    "iov::UNALIGNED","64",
    "iov::UNALIGNED","32",
    "iov::UNALIGNED","16",
    "iov::UNALIGNED","8",
    "iov::UNALIGNED","32",
    "iov::UNALIGNED","64"
  }
}

register_size 128
{
  base_types = {"uint64_t", "uint32_t", "uint16_t", "uint8_t", "float", "double"}
  # provide one implementation for each base_type, use the same sequence as for base_types
  implementations = {
    "return _mm_i64gather_epi64( reinterpret_cast<const long long int *> (p_DataPtr), p_vec,  sizeof(uint64_t) );",

    "return _mm_i32gather_epi32( reinterpret_cast<const int *> (p_DataPtr), p_vec, 4 );//a bit limited",

    "return _mm_set_epi16(
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,7) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,6) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,5) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,4) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,3) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,2) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,1) * 2),
              *reinterpret_cast<uint16_t const *>(reinterpret_cast<uint16_t const *>(p_DataPtr) + _mm_extract_epi16(p_vec,0) * 2)
    );//Possible accessible data range is 65.535/32.767",

    "return _mm_set_epi8(
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,15) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,14) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,13) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,12) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,11) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,10) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,9) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,8) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,7) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,6) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,5) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,4) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,3) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,2) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,1) * 1),
              *reinterpret_cast<uint8_t const *>(reinterpret_cast<uint8_t const *>(p_DataPtr) + _mm_extract_epi8(p_vec,0) * 1)
    );//Possible accessible data range is 255/127",

    "return _mm_i32gather_ps( reinterpret_cast<const float *> (p_DataPtr), p_vec,  sizeof(double) );//a bit limited",

    "return _mm_i64gather_pd( reinterpret_cast<const double *> (p_DataPtr), p_vec,  sizeof(float) );"
  }
  # number of specialized template parameters exclusing the processing style
  nr_additional_template_parameters = 2
  # additional template specializations. If there is more than 1 template argument and more than 1 base type, follow this sequence: {base type 1/argument1, base type 1/argument 2, ..., base type n/argument 1, base type n/argument 2,..., base type n/argument m}
  template_parameters = {
    "iov::UNALIGNED","64",
    "iov::UNALIGNED","32",
    "iov::UNALIGNED","16",
    "iov::UNALIGNED","8",
    "iov::UNALIGNED","32",
    "iov::UNALIGNED","64"
  }
}
